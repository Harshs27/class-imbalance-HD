{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Class Imbalance \n",
        "\n",
        "- Using Neural Graphical Models\n",
        "- Binary Classification"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "# reloads modules automatically before entering the \n",
        "# execution of code typed at the IPython prompt.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "print(sys.prefix)\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# Local imports\n",
        "from ngm.utils import data_processing as dp\n",
        "from ngm.utils.metrics import reportMetrics\n",
        "import ngm.main as ngm"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n/anaconda/envs/kals\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1707103552093
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data for `NGM`\n",
        "- Data: UCI repository"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data \n",
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "uci_data = fetch_ucirepo(id=17)\n",
        "print(uci_data.metadata) \n",
        "features = uci_data.data.features \n",
        "target = uci_data.data.targets \n",
        "\n",
        "# Create the (Xy, G) pair\n",
        "Xy = pd.concat(\n",
        "    [features, pd.get_dummies(target).astype(int).iloc[:, 0]],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Create a fully connected graph\n",
        "G = dp.complete_graph_from_list(Xy.columns)\n",
        "\n",
        "# Create a bi-partite graph in case of multiple labels. \n",
        "\n",
        "print(Xy, G)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n     radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n0      17.99     10.38      122.80  1001.0      0.11840       0.27760   \n1      20.57     17.77      132.90  1326.0      0.08474       0.07864   \n2      19.69     21.25      130.00  1203.0      0.10960       0.15990   \n3      11.42     20.38       77.58   386.1      0.14250       0.28390   \n4      20.29     14.34      135.10  1297.0      0.10030       0.13280   \n..       ...       ...         ...     ...          ...           ...   \n564    21.56     22.39      142.00  1479.0      0.11100       0.11590   \n565    20.13     28.25      131.20  1261.0      0.09780       0.10340   \n566    16.60     28.08      108.30   858.1      0.08455       0.10230   \n567    20.60     29.33      140.10  1265.0      0.11780       0.27700   \n568     7.76     24.54       47.92   181.0      0.05263       0.04362   \n\n     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  \\\n0       0.30010          0.14710     0.2419             0.07871  ...   \n1       0.08690          0.07017     0.1812             0.05667  ...   \n2       0.19740          0.12790     0.2069             0.05999  ...   \n3       0.24140          0.10520     0.2597             0.09744  ...   \n4       0.19800          0.10430     0.1809             0.05883  ...   \n..          ...              ...        ...                 ...  ...   \n564     0.24390          0.13890     0.1726             0.05623  ...   \n565     0.14400          0.09791     0.1752             0.05533  ...   \n566     0.09251          0.05302     0.1590             0.05648  ...   \n567     0.35140          0.15200     0.2397             0.07016  ...   \n568     0.00000          0.00000     0.1587             0.05884  ...   \n\n     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n0       17.33      184.60  2019.0      0.16220       0.66560      0.7119   \n1       23.41      158.80  1956.0      0.12380       0.18660      0.2416   \n2       25.53      152.50  1709.0      0.14440       0.42450      0.4504   \n3       26.50       98.87   567.7      0.20980       0.86630      0.6869   \n4       16.67      152.20  1575.0      0.13740       0.20500      0.4000   \n..        ...         ...     ...          ...           ...         ...   \n564     26.40      166.10  2027.0      0.14100       0.21130      0.4107   \n565     38.25      155.00  1731.0      0.11660       0.19220      0.3215   \n566     34.12      126.70  1124.0      0.11390       0.30940      0.3403   \n567     39.42      184.60  1821.0      0.16500       0.86810      0.9387   \n568     30.37       59.16   268.6      0.08996       0.06444      0.0000   \n\n     concave_points3  symmetry3  fractal_dimension3  Diagnosis_B  \n0             0.2654     0.4601             0.11890            0  \n1             0.1860     0.2750             0.08902            0  \n2             0.2430     0.3613             0.08758            0  \n3             0.2575     0.6638             0.17300            0  \n4             0.1625     0.2364             0.07678            0  \n..               ...        ...                 ...          ...  \n564           0.2216     0.2060             0.07115            0  \n565           0.1628     0.2572             0.06637            0  \n566           0.1418     0.2218             0.07820            0  \n567           0.2650     0.4087             0.12400            0  \n568           0.0000     0.2871             0.07039            1  \n\n[569 rows x 31 columns] Graph with 31 nodes and 465 edges\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707109668082
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning `NGM`\n",
        "\n",
        "### TODO\n",
        "- Report 5-fold CV results. \n",
        "- Set the target value to 0.5 while giving as an input"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "curr_GPU = 'cuda:0'  # TODO: implement the use_device code"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707110725213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ngm.main as ngm\n",
        "\n",
        "# Learning the NMG model\n",
        "model_NGM = ngm.learning(\n",
        "    G, Xy, lambd=1e0,\n",
        "    hidden_dim=200,\n",
        "    epochs=2000, \n",
        "    lr=0.01,\n",
        "    norm_type='min_max',\n",
        "    k_fold=1,\n",
        "    structure_penalty='hadamard'\n",
        ") "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using \"cuda\" compute\nMeans of selected features (radius1                14.127292\ntexture1               19.289649\nperimeter1             91.969033\narea1                 654.889104\nsmoothness1             0.096360\ncompactness1            0.104341\nconcavity1              0.088799\nconcave_points1         0.048919\nsymmetry1               0.181162\nfractal_dimension1      0.062798\nradius2                 0.405172\ntexture2                1.216853\nperimeter2              2.866059\narea2                  40.337079\nsmoothness2             0.007041\ncompactness2            0.025478\nconcavity2              0.031894\nconcave_points2         0.011796\nsymmetry2               0.020542\nfractal_dimension2      0.003795\nradius3                16.269190\ntexture3               25.677223\nperimeter3            107.261213\narea3                 880.583128\nsmoothness3             0.132369\ncompactness3            0.254265\nconcavity3              0.272188\nconcave_points3         0.114606\nsymmetry3               0.290076\nfractal_dimension3      0.083946\nDiagnosis_B             0.627417\ndtype: float64, 31)\nNormalizing the data: min_max\nFold num 0\nSending the data to cuda\nThe data is in cuda, grad should be False: False\nInitializing the NGM model\nNGM model initialized DNN(\n  (MLP): Sequential(\n    (0): Linear(in_features=31, out_features=200, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=200, out_features=200, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=200, out_features=200, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=200, out_features=31, bias=True)\n    (7): Sigmoid()\n  )\n)\n\nFold 0: epoch:0/2000\nTrain: loss=-8.346071243286133, reg=0.10703039914369583, struct=-8.453102111816406\nTest: loss=-8.4149169921875, reg=0.09472859650850296, struct=-8.509645462036133\nTest: loss=-8.42794132232666, reg=0.003504748223349452, struct=-8.431446075439453\nTest: loss=-8.904417991638184, reg=0.004476524889469147, struct=-8.908894538879395\n\nFold 0: epoch:200/2000\nTrain: loss=-8.905684471130371, reg=0.0032103515695780516, struct=-8.908894538879395\nTest: loss=-9.001384735107422, reg=0.004960685968399048, struct=-9.006345748901367\nTest: loss=-10.011021614074707, reg=0.007737325504422188, struct=-10.018758773803711\nTest: loss=-10.477404594421387, reg=0.009992572478950024, struct=-10.487397193908691\n\nFold 0: epoch:400/2000\nTrain: loss=-10.483400344848633, reg=0.003996985498815775, struct=-10.487397193908691\nTest: loss=-10.47840404510498, reg=0.010010865516960621, struct=-10.488414764404297\nTest: loss=-10.829357147216797, reg=0.011480300687253475, struct=-10.840837478637695\nTest: loss=-11.01323127746582, reg=0.01276978850364685, struct=-11.0260009765625\n\nFold 0: epoch:600/2000\nTrain: loss=-11.023367881774902, reg=0.0026332212146371603, struct=-11.0260009765625\nTest: loss=-11.104392051696777, reg=0.012907829135656357, struct=-11.117300033569336\nTest: loss=-11.138136863708496, reg=0.01585269533097744, struct=-11.153989791870117\nTest: loss=-11.496529579162598, reg=0.01433716993778944, struct=-11.51086711883545\n\nFold 0: epoch:800/2000\nTrain: loss=-11.508623123168945, reg=0.0022435402497649193, struct=-11.51086711883545\nTest: loss=-11.356135368347168, reg=0.014535866677761078, struct=-11.370671272277832\nTest: loss=-11.72264575958252, reg=0.0161207877099514, struct=-11.73876667022705\nTest: loss=-11.746129035949707, reg=0.014502105303108692, struct=-11.760631561279297\n\nFold 0: epoch:1000/2000\nTrain: loss=-11.758706092834473, reg=0.0019256012747064233, struct=-11.760631561279297\nTest: loss=-11.73996639251709, reg=0.014611847698688507, struct=-11.754578590393066\nTest: loss=-11.658472061157227, reg=0.015438803471624851, struct=-11.673911094665527\nTest: loss=-11.84231948852539, reg=0.015137622132897377, struct=-11.857457160949707\n\nFold 0: epoch:1200/2000\nTrain: loss=-11.854995727539062, reg=0.002461284166201949, struct=-11.857457160949707\nTest: loss=-11.986740112304688, reg=0.01514523383229971, struct=-12.001885414123535\nTest: loss=-12.02708911895752, reg=0.016537711024284363, struct=-12.04362678527832\nTest: loss=-11.625271797180176, reg=0.01866440661251545, struct=-11.643936157226562\n\nFold 0: epoch:1400/2000\nTrain: loss=-11.640267372131348, reg=0.0036692414432764053, struct=-11.643936157226562\nTest: loss=-11.607437133789062, reg=0.018575046211481094, struct=-11.626011848449707\nTest: loss=-12.252154350280762, reg=0.015805479139089584, struct=-12.267959594726562\nTest: loss=-12.058195114135742, reg=0.016622796654701233, struct=-12.074817657470703\n\nFold 0: epoch:1600/2000\nTrain: loss=-12.073415756225586, reg=0.0014015835477039218, struct=-12.074817657470703\nTest: loss=-12.118690490722656, reg=0.01651959866285324, struct=-12.135210037231445\nTest: loss=-12.263494491577148, reg=0.01691923663020134, struct=-12.280413627624512\nTest: loss=-12.313823699951172, reg=0.01605135202407837, struct=-12.329874992370605\n\nFold 0: epoch:1800/2000\nTrain: loss=-12.326813697814941, reg=0.0030612400732934475, struct=-12.329874992370605\nTest: loss=-12.5690279006958, reg=0.01592971198260784, struct=-12.58495807647705\nTest: loss=-11.897631645202637, reg=0.016093673184514046, struct=-11.913724899291992\nTest: loss=-12.62496280670166, reg=0.014856606721878052, struct=-12.639819145202637\n\n\nBest model selected: Fold 0: epoch:1999/2000:\n                        Train: loss=-12.812704086303711, reg=0.002683572005480528, struct=-12.815387725830078\n                        Test: loss=-12.62496280670166, reg=0.014856606721878052, struct=-12.639819145202637\nStructure Check: prodW=[[0.0014105  0.00126132 0.00167962 0.34175947 0.00360505 0.0010873\n  0.00454236 0.23533888 0.00083683 0.13607441 0.37536603 0.33312067\n  0.23808762 0.34271523 0.43559253 0.08873525 0.00188675 0.0009604\n  0.12312641 0.00123286 0.00096166 0.00129872 0.0016732  0.00585819\n  0.00090893 0.2433985  0.00142982 0.00118529 0.00136138 0.3334345\n  0.00113777]\n [0.00174397 0.00128123 0.0019974  0.34175742 0.00361618 0.00108901\n  0.0045453  0.23533735 0.00084141 0.13607527 0.37536404 0.33312064\n  0.23808663 0.3427139  0.43558982 0.08873791 0.00188903 0.0009657\n  0.1231271  0.00150719 0.0010353  0.00156655 0.00167715 0.00586056\n  0.00113305 0.2433979  0.00165063 0.00142343 0.00158528 0.33343422\n  0.0012878 ]\n [0.00200361 0.00129526 0.00224431 0.34175736 0.00360908 0.00108852\n  0.00454492 0.23533714 0.00084393 0.13607538 0.37536263 0.33311912\n  0.23808555 0.34271243 0.43558887 0.08873638 0.00188937 0.00096817\n  0.12312675 0.00171953 0.00109245 0.00177459 0.00167879 0.00585983\n  0.00130673 0.24339843 0.00182084 0.0016077  0.00175856 0.33343238\n  0.00140311]\n [0.43369612 0.02482167 0.41302973 0.00259187 0.00084603 0.00096831\n  0.00133687 0.00166348 0.00523438 0.00223951 0.00209672 0.0027405\n  0.00149402 0.00201335 0.00259456 0.00210837 0.00191391 0.00568809\n  0.00168749 0.35589474 0.09560426 0.347984   0.00424126 0.00122475\n  0.29080087 0.00288933 0.28591874 0.30882016 0.29038438 0.00213379\n  0.19403656]\n [0.43367967 0.02483161 0.41301984 0.00343023 0.00088734 0.0009776\n  0.00135253 0.00223596 0.00524092 0.00257612 0.00301398 0.00356448\n  0.00207534 0.00285386 0.00366132 0.00235193 0.00192449 0.00569892\n  0.00199062 0.35588753 0.09560627 0.34797272 0.00425591 0.00124955\n  0.29079625 0.0034871  0.2859178  0.30881545 0.29037896 0.00295668\n  0.19404072]\n [0.00107382 0.0012422  0.00135879 0.3417595  0.00360588 0.00108663\n  0.00454156 0.23534015 0.00083269 0.1360741  0.37536845 0.33312201\n  0.23808958 0.34271726 0.43559384 0.08873392 0.00188537 0.00095596\n  0.12312717 0.00095653 0.00088738 0.00102866 0.00167011 0.00585743\n  0.00068315 0.243397   0.00120798 0.00094566 0.00113598 0.33343408\n  0.00098716]\n [0.43355855 0.02484341 0.41290745 0.00874049 0.00094347 0.00099469\n  0.00143373 0.00589229 0.00525174 0.00469093 0.00884689 0.00874091\n  0.00577446 0.00817915 0.01042999 0.00372823 0.00195359 0.00570948\n  0.00390411 0.3557881  0.09558911 0.347878   0.00427773 0.00133999\n  0.29071164 0.00726973 0.2858439  0.30873075 0.29030252 0.00813928\n  0.19399059]\n [0.43370104 0.02481875 0.4130335  0.00216051 0.00083634 0.00096549\n  0.00133002 0.00136816 0.00523199 0.00206669 0.00162413 0.0023184\n  0.00119475 0.00158071 0.00204535 0.00199075 0.00191042 0.00568488\n  0.00153186 0.35589832 0.09560295 0.34798786 0.00423787 0.00121541\n  0.290804   0.00258237 0.28591996 0.30882263 0.29038626 0.0017133\n  0.19403598]\n [0.00164858 0.00127784 0.00190764 0.34175733 0.00363027 0.0010917\n  0.0045482  0.23533413 0.00084318 0.13607581 0.37536192 0.33312324\n  0.2380846  0.34271324 0.435589   0.08875076 0.00189126 0.00096715\n  0.12312648 0.00143059 0.00101536 0.0014904  0.00167891 0.00586553\n  0.00107022 0.2433989  0.00159028 0.00135711 0.00152302 0.333438\n  0.00124726]\n [0.43369466 0.02482078 0.41302818 0.0027375  0.00084852 0.00096765\n  0.0013381  0.00176426 0.00523392 0.00229706 0.00225709 0.00288159\n  0.00159581 0.00215939 0.00278045 0.00214287 0.00191402 0.00568731\n  0.00173958 0.3558937  0.09560296 0.34798342 0.0042412  0.0012261\n  0.29080063 0.002993   0.28591725 0.30881953 0.29038382 0.00227642\n  0.19403486]\n [0.43370193 0.02481904 0.4130345  0.00198827 0.00083539 0.00096548\n  0.00132905 0.0012494  0.00523195 0.00199827 0.00143484 0.00215082\n  0.00107468 0.00140797 0.00182578 0.00194675 0.00190968 0.00568533\n  0.00146989 0.35589942 0.09560344 0.34798852 0.00423737 0.00121282\n  0.29080495 0.00246002 0.28592077 0.30882365 0.29038715 0.00154575\n  0.19403727]\n [0.43370026 0.02482049 0.41303378 0.00214185 0.00083686 0.00096709\n  0.00133075 0.0013541  0.00523233 0.00206    0.00160271 0.0023009\n  0.00118111 0.00156207 0.00202114 0.00198916 0.00191095 0.00568636\n  0.00152511 0.355899   0.09560318 0.3479874  0.00423899 0.00121615\n  0.29080394 0.00256919 0.2859204  0.3088226  0.29038593 0.00169467\n  0.19403756]\n [0.4336983  0.02482035 0.41303152 0.00241163 0.00083779 0.00096691\n  0.00133383 0.00154023 0.00523312 0.00216712 0.00189932 0.00256349\n  0.00136915 0.00183253 0.00236505 0.00205793 0.00191228 0.00568678\n  0.00162231 0.3558961  0.09560388 0.34798554 0.00423942 0.00122026\n  0.29080212 0.00276104 0.2859194  0.3088214  0.29038537 0.0019573\n  0.1940366 ]\n [0.43370137 0.02482007 0.4130346  0.00203149 0.00084092 0.00096675\n  0.0013296  0.00127702 0.00523244 0.00201645 0.0014808  0.00219382\n  0.00110312 0.0014515  0.00188021 0.00196192 0.00191057 0.00568647\n  0.00148508 0.35589936 0.09560379 0.34798798 0.004239   0.00121481\n  0.29080412 0.00249012 0.28592098 0.30882305 0.29038674 0.0015868\n  0.19403806]\n [0.43369815 0.0248209  0.41303158 0.00236622 0.00084745 0.00096763\n  0.00133491 0.00150737 0.00523359 0.00214976 0.00184846 0.00252044\n  0.0013363  0.00178709 0.00230687 0.00204895 0.00191267 0.00568734\n  0.00160579 0.35589656 0.09560391 0.34798554 0.0042401  0.00122083\n  0.2908027  0.00272869 0.28592014 0.3088218  0.29038563 0.00191416\n  0.19403696]\n [0.4336767  0.02483018 0.4130161  0.00377292 0.00088246 0.0009762\n  0.00136342 0.00247475 0.00523865 0.00271122 0.00339265 0.00389503\n  0.00231585 0.00319782 0.00409955 0.00242453 0.00192332 0.00569616\n  0.00211344 0.35588408 0.09560356 0.34797028 0.00425125 0.00125026\n  0.2907928  0.00373303 0.28591323 0.3088123  0.2903759  0.00329388\n  0.19403633]\n [0.43356153 0.02487285 0.4129235  0.00804628 0.00103095 0.00102117\n  0.00144671 0.00538648 0.00526675 0.00442992 0.00806344 0.00808769\n  0.00527337 0.00748197 0.00953324 0.00364652 0.00197368 0.00573718\n  0.00365595 0.35580817 0.09560332 0.34788463 0.00430688 0.00136601\n  0.2907273  0.00677576 0.2858727  0.30875045 0.29031512 0.00746598\n  0.19402474]\n [0.00272815 0.00133971 0.00293722 0.3417529  0.0036298  0.00109275\n  0.00454982 0.23533216 0.00085445 0.1360775  0.37535647 0.33311906\n  0.23808135 0.34270877 0.4355822  0.0887441  0.00189454 0.00098209\n  0.12312696 0.00231828 0.00125288 0.00235711 0.00168823 0.0058651\n  0.00179744 0.24339664 0.00230337 0.00212849 0.00224767 0.33342957\n  0.00173305]\n [0.43370232 0.02481833 0.41303438 0.00207584 0.0008322  0.00096536\n  0.00132904 0.00130909 0.00523155 0.00203343 0.0015306  0.00223628\n  0.00113518 0.00149575 0.00193709 0.00197119 0.00191021 0.00568382\n  0.00150133 0.3558988  0.09560268 0.34798872 0.00423813 0.00121443\n  0.29080418 0.00252163 0.28592047 0.3088229  0.2903861  0.00162889\n  0.19403525]\n [0.00156759 0.0012717  0.0018297  0.34175786 0.00362596 0.00108914\n  0.00454726 0.2353364  0.00083973 0.13607545 0.3753639  0.33312175\n  0.23808616 0.3427145  0.43559045 0.08873979 0.00188877 0.0009639\n  0.12312669 0.00136275 0.00099659 0.00142506 0.00167635 0.00586141\n  0.00101494 0.24339834 0.00153484 0.00129807 0.0014674  0.33343717\n  0.00120921]\n [0.00139089 0.00126082 0.00166116 0.34175882 0.00361167 0.001088\n  0.00454344 0.23533845 0.00083691 0.13607469 0.37536612 0.33312163\n  0.23808761 0.3427157  0.43559217 0.08873598 0.00188718 0.00096086\n  0.12312662 0.00121728 0.0009574  0.00128319 0.00167339 0.00585893\n  0.00089622 0.2433978  0.00141767 0.00117191 0.00134876 0.33343476\n  0.00112964]\n [0.00178171 0.00128317 0.00203329 0.34175786 0.00361885 0.00108897\n  0.00454461 0.23533683 0.00084201 0.1360751  0.3753632  0.33312038\n  0.23808561 0.34271324 0.43558982 0.08873828 0.00188924 0.00096615\n  0.12312646 0.00153805 0.00104359 0.00159664 0.00167751 0.00586066\n  0.00115814 0.24339847 0.00167528 0.00144991 0.0016103  0.33343536\n  0.00130446]\n [0.03991833 0.00351345 0.03837743 0.34028688 0.00409462 0.00122507\n  0.00471668 0.23424867 0.00133545 0.13562977 0.3736443  0.3317655\n  0.23699285 0.3411923  0.43363997 0.08865066 0.00208844 0.00152093\n  0.12266218 0.03287429 0.00946658 0.03220604 0.00210108 0.00601622\n  0.02675814 0.24244717 0.02686583 0.02863801 0.02717179 0.33202428\n  0.0184246 ]\n [0.43331465 0.02486146 0.41268757 0.01417449 0.00105812 0.00102325\n  0.00151623 0.0096246  0.0052686  0.0068592  0.0148093  0.0140471\n  0.00955406 0.01362926 0.01735364 0.00517007 0.00199115 0.00573545\n  0.00586187 0.3555981  0.09555152 0.3476867  0.00431359 0.00144643\n  0.29055518 0.01113991 0.28570372 0.30856907 0.29015276 0.01344873\n  0.193906  ]\n [0.00130711 0.00125561 0.00158121 0.34175915 0.00360853 0.00108718\n  0.00454265 0.23533942 0.00083563 0.13607396 0.37536687 0.33312094\n  0.23808828 0.34271562 0.4355928  0.08873421 0.00188647 0.00095935\n  0.12312658 0.0011483  0.00093886 0.0012159  0.00167214 0.00585811\n  0.00083999 0.24339807 0.00136198 0.00111207 0.00129251 0.33343542\n  0.00109189]\n [0.43369326 0.02482154 0.41302705 0.00290768 0.00084137 0.0009682\n  0.00133983 0.00188183 0.0052341  0.00236456 0.00244419 0.00304694\n  0.00171461 0.00232999 0.00299733 0.00218622 0.00191477 0.00568782\n  0.00180093 0.35589185 0.09560374 0.34798166 0.00424172 0.00122843\n  0.2907986  0.00311401 0.28591663 0.30881786 0.29038247 0.00244047\n  0.1940349 ]\n [0.00139711 0.00126252 0.00166776 0.34175858 0.00361928 0.00108947\n  0.00454523 0.23533723 0.00083815 0.13607529 0.37536514 0.3331228\n  0.23808675 0.34271535 0.4355915  0.08874116 0.00188836 0.00096251\n  0.12312675 0.00122348 0.00095943 0.00128856 0.00167552 0.00586131\n  0.000901   0.24339788 0.00142315 0.00117711 0.00135364 0.33343577\n  0.00113428]\n [0.00150972 0.00126777 0.00177462 0.34175894 0.00361119 0.00108836\n  0.00454344 0.2353379  0.00083861 0.13607448 0.37536478 0.33312094\n  0.2380865  0.3427144  0.43559164 0.08873787 0.00188789 0.00096268\n  0.12312597 0.00131494 0.00098381 0.00137847 0.00167518 0.00585972\n  0.0009758  0.24339887 0.00149596 0.00125632 0.00142819 0.3334358\n  0.00118321]\n [0.00241106 0.00132083 0.00263407 0.34175453 0.00362366 0.00109198\n  0.00454906 0.23533364 0.00085048 0.136077   0.375359   0.33311993\n  0.23808332 0.34271044 0.43558472 0.08874447 0.00189293 0.00097646\n  0.12312736 0.0020565  0.00118283 0.00210224 0.00168517 0.00586438\n  0.0015821  0.24339725 0.00209251 0.00190024 0.00203343 0.33343092\n  0.00158888]\n [0.4337012  0.02481945 0.41303372 0.00209672 0.00083779 0.00096599\n  0.0013314  0.00132318 0.00523237 0.00204184 0.00155331 0.00225704\n  0.00114953 0.00151673 0.00196369 0.00197664 0.00191061 0.00568553\n  0.00150887 0.3558985  0.09560374 0.3479877  0.00423824 0.00121527\n  0.2908042  0.00253712 0.28592092 0.30882314 0.29038662 0.00165105\n  0.19403687]\n [0.0014255  0.00126327 0.00169424 0.34175852 0.00362315 0.00108882\n  0.0045435  0.23533757 0.00083818 0.13607466 0.37536523 0.33312207\n  0.23808648 0.34271497 0.43559176 0.08873832 0.00188811 0.00096213\n  0.12312622 0.00124611 0.00096528 0.00131088 0.00167464 0.00586045\n  0.00091953 0.24339783 0.00144108 0.00119652 0.00137208 0.3334369\n  0.00114578]], S=tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n"
        }
      ],
      "execution_count": 92,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707111749105
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_feature = 'Diagnosis_B'\n",
        "Xy_test = Xy.copy()\n",
        "Xy_test[target_feature] = 0.5\n",
        "pred_Xy = ngm.fit_regression_direct(\n",
        "    model_NGM, \n",
        "    Xy_test,\n",
        "    target_feature,\n",
        "    BATCH_SIZE=1000,\n",
        "    VERBOSE=True, \n",
        "    USE_CUDA=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using \"cuda\" compute\ntorch.Size([569, 31])\n"
        }
      ],
      "execution_count": 98,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707111895487
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Xy[target_feature]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 99,
          "data": {
            "text/plain": "0      0.000392\n1      0.019045\n2      0.003468\n3      0.028756\n4      0.035871\n         ...   \n564    0.000535\n565    0.010043\n566    0.357706\n567    0.000164\n568    0.982753\nName: Diagnosis_B, Length: 569, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 99,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707111898456
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xy_test[target_feature].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 95,
          "data": {
            "text/plain": "Diagnosis_B\n0.5    569\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 95,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707111753384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics\n",
        "from ngm.utils import metrics \n",
        "\n",
        "print(metrics.compute_metrics(pred_Xy[target_feature], Xy[target_feature]))\n",
        "print(f'(AUC, AUPR) =  {metrics.get_auc(Xy[target_feature], pred_Xy[target_feature])}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'mae': 0.13375298933205076, 'rmse': 0.21857334672349857, 'r2': 0.7956310752690731, 'rel_err': 270954957236448.22}\nmax acc = 0.9648506151142355\n(AUC, AUPR) =  (0.9762433275196871, 0.9760829664937986)\n"
        }
      ],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707111753514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the local and global models\n",
        "import pickle \n",
        "\n",
        "# folder = '../../../externalData/vichar_models/'\n",
        "# filename = 'mnist_NGM_H500L10.pickle'\n",
        "\n",
        "# with open(folder+filename, 'wb') as handle: # file object\n",
        "#     pickle.dump([model_NGM], handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1707111753636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "kals"
    },
    "kernelspec": {
      "name": "kals",
      "language": "python",
      "display_name": "kals"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}